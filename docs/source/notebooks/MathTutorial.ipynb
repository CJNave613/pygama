{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pygama Math and Fitting\n",
    "\n",
    "The goal of this notebook is to illustrate the conventions of the functions stored in `pygama.math` and how they can be used to fit data. We will also go over how to write new math distributions. \n",
    "\n",
    "### Set up the Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygama.math as math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 4)\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"font.size\"] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Distributions \n",
    "\n",
    "All statistical distributions are stored in `pygama.math.functions` and can be imported through the module `pygama.math.distributions`. Let's import a plain-old Gaussian and look at the methods it has associated with it! And then, at the end of this section, we can look at the conventions and how to write a new distribution. \n",
    "\n",
    "Let's also fix the shape parameters for the Gaussian.\n",
    "\n",
    "For comparison's sake, let's also import `scipy`'s version of the Gaussian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygama.math.distributions import gaussian\n",
    "from scipy.stats import norm\n",
    "\n",
    "mu = 2.5\n",
    "sigma = 0.7\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "object_methods = [\n",
    "    method_name\n",
    "    for method_name in dir(gaussian)\n",
    "    if callable(getattr(gaussian, method_name))\n",
    "]\n",
    "print(object_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geez, there are a lot of methods. Let's hone in on a couple: \n",
    "### .pdf and .cdf \n",
    "\n",
    "These are just your bread and butter probability density and cumulative density functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_pdf = gaussian.pdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, gauss_pdf, label=\"Pygama Gaussian PDF\", c=\"k\")\n",
    "plt.plot(x, norm.pdf(x, mu, sigma), label=\"Scipy Gaussian PDF\", ls=\":\", alpha=1, c=\"r\")\n",
    "plt.title(\"PDF of a Gaussian Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_cdf = gaussian.cdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, gauss_cdf, label=\"Gaussian CDF\", c=\"k\")\n",
    "plt.plot(x, norm.cdf(x, mu, sigma), label=\"Scipy Gaussian CDF\", ls=\":\", alpha=1, c=\"r\")\n",
    "plt.title(\"CDF of a Gaussian Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so that's fine and dandy, what's so special about a class that reproduces `scipy` results? \n",
    "\n",
    "Well, every function in `pygama.math.functions` subclasses `scipy`'s `rv_continuous` class: this allows access to methods that `scipy` automagically computes. Let's look at a few \n",
    "\n",
    "### What `rv_continuous` subclassing gets us: `.rvs`, `.logpdf`, `.sf`... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_log_pdf = gaussian.logpdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, gauss_log_pdf, label=\"Gaussian Log PDF\", c=\"k\")\n",
    "plt.plot(\n",
    "    x, norm.logpdf(x, mu, sigma), label=\"Scipy Gaussian Log PDF\", ls=\":\", alpha=1, c=\"r\"\n",
    ")\n",
    "plt.title(\"Log PDF of a Gaussian Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sf = gaussian.sf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, gauss_sf, label=\"Gaussian SF\", c=\"k\")\n",
    "plt.plot(x, norm.sf(x, mu, sigma), label=\"Scipy Gaussian SF\", ls=\":\", alpha=1, c=\"r\")\n",
    "plt.title(\"Survival Fraction of a Gaussian Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for something really useful, random sampling: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = gaussian.rvs(mu, sigma, size=1000, random_state=1)\n",
    "\n",
    "hist, bins = np.histogram(random_sample, bins=100, range=(-10, 10))\n",
    "plt.step(\n",
    "    bins[1:], hist / np.sum(hist) * np.sum(gauss_pdf), label=\"Randomly Sampled Data\"\n",
    ")\n",
    "plt.plot(x, gauss_pdf, label=\"Gaussian PDF\")\n",
    "plt.title(\"Comparison of Randomly Sampled Data with Underlying PDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We get access to `scipy`'s `rv_continuous` methods for free\n",
    "\n",
    "If we take a look at the actual code for the definition of `pygama.math.functions.gaussian` we see that there is no direct implementation of methods for `.rvs` or `.logpdf`! We get access to all these methods for free. All we have to do is subclass `rv_continuous` and write definitions for `_pdf` and `_cdf` \n",
    "\n",
    "Now, the drawback: the functions `_pdf` and `_cdf` that `rv_continuous` uses are slow. Let's see this by comparing to the function that actually computes the pdf: \n",
    "### But the `.pdf` and `.cdf` methods are slow! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 4 -n 10000\n",
    "gauss_pdf = gaussian.pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mu, sigma):\n",
    "    if sigma == 0:\n",
    "        invs = np.inf\n",
    "    else:\n",
    "        invs = 1.0 / sigma\n",
    "    z = (x - mu) * invs\n",
    "    invnorm = invs / np.sqrt(2 * np.pi)\n",
    "    return np.exp(-0.5 * z**2) * invnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 4 -n 10000\n",
    "gauss_pdf = gaussian_pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast methods: `.get_pdf` and `.get_cdf`\n",
    "\n",
    "Because the overloaded `rv_continuous` implementations of `pdf` and `cdf` are very slow, we have implemented fast versions of these two methods, named `get_pdf` and `get_cdf`. \n",
    "\n",
    "Each of these fast methods call a `numba.njit`-wrapped function --- a just-in-time compiled function --- that runs super fast. \n",
    "\n",
    "We keep the `.pdf` and `.cdf` because they give us access to `scipy` methods we might want to use, but we write these faster methods so that we can fit distributions quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_get_pdf = gaussian.get_pdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, gauss_get_pdf, label=\"Pygama Gaussian Get_PDF\", c=\"k\")\n",
    "plt.plot(x, norm.pdf(x, mu, sigma), label=\"Scipy Gaussian PDF\", ls=\":\", alpha=1, c=\"r\")\n",
    "plt.title(\"PDF of a Gaussian Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's good that it reproduces the scipy results numerically. But how fast does it run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 4 -n 10000\n",
    "gauss_pdf = gaussian.get_pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, we're even faster than the function we defined above! That's the power of just-in-time compiled code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The remaining methods are helpful for binned and unbinned fitting: `norm_pdf`, `norm_cdf`, `pdf_ext` and `cdf_ext`\n",
    "\n",
    "For `pygama` our default way of fitting distributions is to use the `Iminuit` package. `Iminuit` has several different ways to fit binned and unbinned data by performing either extended or unextended fits. These fitting methods require functions with different properties. The way `pygama` functions interact with `Iminuit` is as follows: \n",
    "\n",
    "1. `norm_pdf` is used for unbinned fits, which require a pdf that is normalized to 1 on the fitting range \n",
    "2. `norm_cdf` is used for binned fits, which require a cdf that derived from a pdf that is normalized to 1 on the fitting range \n",
    "3. `pdf_ext` is used for extended unbinned fits, and the function is required to return a tuple of the support-normalized pdf integrated over the data window, and the scaled support-normalized pdf.\n",
    "4. `cdf_ext` is used for extended binned fits, and just returns the scaled support-derived cdf\n",
    "\n",
    "Let's illustrate some fitting in action, and why some of these weird definitions are required \n",
    "### Import Iminuit and create data to fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iminuit import cost, Minuit\n",
    "\n",
    "xr = (-4, 4)  # xrange\n",
    "mu = 0.5\n",
    "sigma = 3\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "xdata = rng.normal(mu, sigma, size=1000)\n",
    "xdata = xdata[(xr[0] < xdata) & (xdata < xr[1])]\n",
    "\n",
    "n, xe = np.histogram(xdata, bins=50, range=xr)\n",
    "cx = 0.5 * (xe[1:] + xe[:-1])\n",
    "dx = np.diff(xe)\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "plt.plot(xdata, np.zeros_like(xdata), \"|\", alpha=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try an unbinned fit using the correct `norm_pdf` and the incorrect `get_pdf`\n",
    "\n",
    "We first note that the method `norm_pdf` has arguments `x_lower, x_upper, mu, sigma` where `x_lower, x_upper` are the bounds of the fitting range to ensure that the pdf is normalized to unity on. So, we therefore fix these fit parameters in Iminuit. \n",
    "\n",
    "We also show a fit with `get_pdf` to show that the fit returns the incorrect results! We keep the `get_pdf` methods in `pygama` because they are useful if we ever need to numerically compute something quickly, or if we do a least squares fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.UnbinnedNLL(xdata, gaussian.norm_pdf)\n",
    "\n",
    "m_norm = Minuit(c, x_lower=xr[0], x_upper=xr[1], mu=0.4, sigma=0.2)\n",
    "m_norm.fixed[\"x_lower\", \"x_upper\"] = True\n",
    "m_norm.limits[\"mu\", \"sigma\"] = (0, None)\n",
    "m_norm.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.UnbinnedNLL(xdata, gaussian.get_pdf)\n",
    "\n",
    "m = Minuit(c, mu=0.4, sigma=0.2)\n",
    "m.limits[\"mu\", \"sigma\"] = (0, None)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "xm = np.linspace(*xr)\n",
    "plt.plot(\n",
    "    xm, gaussian.norm_pdf(xm, *m_norm.values) * len(xdata) * dx[0], label=\"norm_pdf fit\"\n",
    ")\n",
    "plt.plot(xm, gaussian.get_pdf(xm, *m.values) * len(xdata) * dx[0], label=\"get_pdf fit\")\n",
    "plt.plot(\n",
    "    xm, gaussian.get_pdf(xm, mu, sigma) * len(xdata) * dx[0], label=\"True Distribution\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `norm_pdf` does a much better job of fitting the actual underlying distribution and reproducing the correct $\\mu,\\sigma$ parameters\n",
    "\n",
    "### try an extended unbinned fit \n",
    "The parameters for the `pdf_ext` are `area, x_lo, x_hi, mu, sigma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedUnbinnedNLL(xdata, gaussian.pdf_ext)\n",
    "\n",
    "m = Minuit(c, area=500, x_lo=xr[0], x_hi=xr[1], mu=0.1, sigma=0.9)\n",
    "m.fixed[\"x_lo\", \"x_hi\"] = True\n",
    "m.limits[\"area\", \"mu\", \"sigma\"] = (0, None)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "xm = np.linspace(*xr)\n",
    "plt.plot(xm, gaussian.pdf_ext(xm, *m.values)[1] * dx[0], label=\"fit\")\n",
    "plt.plot(\n",
    "    xm, gaussian.pdf_ext(xm, 1000, xr[0], xr[1], mu, sigma)[1] * dx[0], label=\"actual\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pdf_ext` function correctly fits the area of the curve! \n",
    "\n",
    "### Binned fits using `norm_cdf` and the incorrect `get_cdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.BinnedNLL(n, xe, gaussian.norm_cdf)\n",
    "\n",
    "m_norm = Minuit(c, x_lower=xr[0], x_upper=xr[1], mu=0.4, sigma=0.2)\n",
    "m_norm.fixed[\"x_lower\", \"x_upper\"] = True\n",
    "m_norm.limits[\"mu\", \"sigma\"] = (0.1, None)\n",
    "m_norm.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.BinnedNLL(n, xe, gaussian.get_cdf)\n",
    "\n",
    "m = Minuit(c, mu=0.4, sigma=0.2)\n",
    "m.limits[\"mu\", \"sigma\"] = (0.1, None)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "plt.stairs(\n",
    "    np.diff(gaussian.norm_cdf(xe, *m_norm.values)) * len(xdata),\n",
    "    xe,\n",
    "    label=\"norm_cdf fit\",\n",
    ")\n",
    "plt.stairs(\n",
    "    np.diff(gaussian.get_cdf(xe, *m.values)) * len(xdata), xe, label=\"get_cdf fit\"\n",
    ")\n",
    "plt.stairs(\n",
    "    np.diff(gaussian.get_cdf(xe, mu, sigma)) * len(xdata),\n",
    "    xe,\n",
    "    label=\"underlying distribution\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, extended binned fits with `cdf_ext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedBinnedNLL(n, xe, gaussian.cdf_ext)\n",
    "\n",
    "m = Minuit(c, area=500, mu=0.1, sigma=0.9)\n",
    "m.limits[\"area\", \"mu\", \"sigma\"] = (0, None)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "plt.stairs(np.diff(gaussian.cdf_ext(xe, *m.values)), xe, label=\"fit\")\n",
    "plt.stairs(np.diff(gaussian.cdf_ext(xe, 1000, mu, sigma)), xe, label=\"underlying\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing our own `pygama.math` distribution: conventions and requirements \n",
    "\n",
    "Let's write a Cauchy distribution. Recall that a Cauchy distribution has support over the real line, and has a pdf like \n",
    "\n",
    "$pdf(x, \\mu,\\sigma) = \\frac{1}{\\pi\\sigma\\left[1+\\left(\\frac{x-\\mu}{\\sigma}\\right)^2\\right]}$\n",
    "\n",
    "and a cdf:\n",
    "\n",
    "$cdf(x, \\mu,\\sigma) = \\frac{1}{\\pi}\\arctan\\left(\\frac{x-\\mu}{\\sigma}\\right)+\\frac{1}{2}$\n",
    "\n",
    "## What we need to define a distribution class\n",
    "We need four functions that our class methods will call and their arguments, and they all should be numbafied \n",
    "\n",
    "1. A PDF, normalized to the support. Args: x, mu, sigma\n",
    "2. A CDF, derived from the support normalized PDF. Args: x, mu, sigma\n",
    "3. A scaled PDF. Args: x, area, mu, sigma\n",
    "4. A scaled CDF. Args: x, area, mu, sigma\n",
    "\n",
    "The convention is to name these functions `nb_distribution_pdf` and `nb_distribution_scaled_cdf` for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "# here we set some parameters to ensure that numba will compute things as quickly as possible\n",
    "kwd_parallel = {\"parallel\": True, \"fastmath\": True}\n",
    "kwd = {\"parallel\": False, \"fastmath\": True}\n",
    "\n",
    "# define the pdf\n",
    "@nb.njit(**kwd_parallel)\n",
    "def nb_cauchy_pdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        The input data\n",
    "    lamb\n",
    "        The rate\n",
    "    mu\n",
    "        The amount to shift the distribution\n",
    "    sigma\n",
    "        The amount to scale the distribution\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.empty_like(x, dtype=np.float64)\n",
    "    # we want to do a loop because it is faster with parallelization\n",
    "    for i in nb.prange(x.shape[0]):\n",
    "        y[i] = (x[i] - mu) / sigma\n",
    "        y[i] = 1 / (np.pi * sigma * (1 + y[i] ** 2))\n",
    "    return y\n",
    "\n",
    "\n",
    "# define the cdf\n",
    "@nb.njit(**kwd_parallel)\n",
    "def nb_cauchy_cdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        The input data\n",
    "    lamb\n",
    "        The rate\n",
    "    mu\n",
    "        The amount to shift the distribution\n",
    "    sigma\n",
    "        The amount to scale the distribution\n",
    "    \"\"\"\n",
    "    y = np.empty_like(x, dtype=np.float64)\n",
    "    for i in nb.prange(x.shape[0]):\n",
    "        y[i] = (x[i] - mu) / sigma\n",
    "        y[i] = (1 / np.pi) * np.arctan(y[i]) + 0.5\n",
    "    return y\n",
    "\n",
    "\n",
    "# define the scaled pdf, can't use parallelization here because there is no outer for-loop\n",
    "@nb.njit(**kwd)\n",
    "def nb_cauchy_scaled_pdf(\n",
    "    x: np.ndarray, area: float, mu: float, sigma: float\n",
    ") -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        The input data\n",
    "    area\n",
    "        The prefactor to scale the pdf by\n",
    "    lamb\n",
    "        The rate\n",
    "    mu\n",
    "        The amount to shift the distribution\n",
    "    sigma\n",
    "        The amount to scale the distribution\n",
    "    \"\"\"\n",
    "    return area * nb_cauchy_pdf(x, mu, sigma)\n",
    "\n",
    "\n",
    "# define the scaled cdf, can't use parallelization here because there is no outer for-loop\n",
    "@nb.njit(**kwd)\n",
    "def nb_cauchy_scaled_cdf(\n",
    "    x: np.ndarray, area: float, mu: float, sigma: float\n",
    ") -> np.ndarray:\n",
    "    r\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    x\n",
    "        The input data\n",
    "    area\n",
    "        The prefactor to scale the pdf by\n",
    "    lamb\n",
    "        The rate\n",
    "    mu\n",
    "        The amount to shift the distribution\n",
    "    sigma\n",
    "        The amount to scale the distribution\n",
    "    \"\"\"\n",
    "    return area * nb_cauchy_cdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we create a class using these four functions \n",
    "\n",
    "Each `pygama` distribution class subclasses `pygama_continuous`, which itself is a subclass of `rv_continuous`. \n",
    "\n",
    "#### An aside on the ordering of parameters: \n",
    "In the following the term \"shape parameter\" refers to a specific variable used to define a distribution that is not an overall scaling (which I call $\\mu$) or shifting (which I call $\\sigma$). An example of shape parameters would be the $\\beta, m$ parameters in a crystal ball function. The location and scale ($\\mu, \\sigma$) parameters have a more specific definition --- akin to what `scipy` does. If a $\\mu, \\sigma$ value is present, then the entire distribution is shifted and scaled; this can be achieved by transforming $y = \\frac{x-\\mu}{\\sigma}$ and computing $pdf(y)/\\sigma$ ( where the factor of $1/\\sigma$ comes from the Jacobian). \n",
    "\n",
    "The ordering of parameters is as follows, using whichever are needed for a function: \n",
    "`x, area, x_lower, x_upper, shapes, ..., mu, sigma`\n",
    "\n",
    "Where `x_lower` and `x_upper` are the lower and upper bounds to evaluate a function on.\n",
    "\n",
    "#### Now, back to require methods\n",
    "\n",
    "The class name has the format `distribution_name_gen` and it must include the following methods with their arguments:\n",
    "\n",
    "1. `_pdf(self, x, shapes)`:\n",
    "\n",
    "    This is an overloading of the `scipy` method for the pdf. Because `scipy` first computes $\\frac{x-\\mu}{\\sigma}$ and $pdf/\\sigma$, we need to call `nb_distribution_pdf` with $\\mu = 0$ and $\\sigma = 1$. If shape parameters are present, `nb_distribution_pdf` must also be called with `shape_param[0]` because `scipy` passes an array of shape parameters to the function calls. Finally, `x.flags.writeable = True` must be passed so that `numba` can operate as expected on arrays. \n",
    "    \n",
    "  \n",
    "2. `_cdf(self, x, shapes)`:\n",
    "\n",
    "    This is an overloading of the `scipy` method for the cdf. The same format applies as for the pdf. \n",
    "       \n",
    "       \n",
    "3. `get_pdf(x, shapes, mu, sigma)`: \n",
    "\n",
    "    This is a direct call to the fast `nb_distribution_pdf`\n",
    "  \n",
    "  \n",
    "4. `get_pdf(x, shapes, mu, sigma)`: \n",
    "\n",
    "    This is a direct call to the fast `nb_distribution_cdf`\n",
    "    \n",
    "    \n",
    "5. `norm_pdf(x, x_lower, x_upper, shapes, mu, sigma)`:\n",
    "\n",
    "    In the case that the support of the distribution is the entire real line, this calls a `pygama_continuous` super method that normalizes the pdf to unity on the range $[x_{lower},x_{upper}]$ by computing $\\frac{pdf(x)}{cdf(x_{upper})- cdf(x_{lower})}$. If the distribution is defined on a limited domain, this function needs to be directly overloaded -- see `pygama.math.functions.step` for an example. \n",
    "    \n",
    "    \n",
    "6. `norm_cdf(x, x_lower, x_upper, shapes, mu, sigma)`:\n",
    "\n",
    "    In the case that the support of the distribution is the entire real line, this calls a `pygama_continuous` super method that derives the cdf from a pdf that is normalized to unity on the range $[x_{lower},x_{upper}]$ by computing $\\frac{cdf(x)}{cdf(x_{upper})- cdf(x_{lower})}$. If the distribution is defined on a limited domain, this function needs to be directly overloaded -- see `pygama.math.functions.step` for an example.\n",
    "    \n",
    "    \n",
    "7. `pdf_ext(x, area, x_lower, x_upper, shapes, mu, sigma)`: \n",
    "\n",
    "    A function that returns both the integral of the support-normalized pdf on the interval $[x_{lower},x_{upper}]$, as well as the support-normalized pdf on that range as well. The fastest way to compute these is to return `np.diff(nb_distribution_scaled_cdf(np.array([x_lower, x_upper]), area, shapes, mu, sigma))` and `nb_distribution_scaled_pdf(x, area, shapes, mu, sigma)`\n",
    "  \n",
    "  \n",
    "8. `cdf_ext(x, area, shapes, mu, sigma)`:\n",
    "\n",
    "    A function that returns just the scaled cdf, `nb_distribution_scaled_cdf(x, area, shapes, mu, sigma)`\n",
    "    \n",
    "    \n",
    "9. `req_args(self)`: \n",
    "\n",
    "    A function that returns a tuple with the strings of the names of the required shape parameters and mu and sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygama.math.functions.pygama_continuous import pygama_continuous\n",
    "\n",
    "\n",
    "class cauchy_gen(pygama_continuous):\n",
    "    def _pdf(self, x: np.ndarray) -> np.ndarray:\n",
    "        x.flags.writeable = True\n",
    "        return nb_cauchy_pdf(x, 0, 1)\n",
    "\n",
    "    def _cdf(self, x: np.ndarray) -> np.ndarray:\n",
    "        x.flags.writeable = True\n",
    "        return nb_cauchy_cdf(x, 0, 1)\n",
    "\n",
    "    def get_pdf(self, x: np.ndarray, mu: float, sigma: float) -> np.ndarray:\n",
    "        return nb_cauchy_pdf(x, mu, sigma)\n",
    "\n",
    "    def get_cdf(self, x: np.ndarray, mu: float, sigma: float) -> np.ndarray:\n",
    "        return nb_cauchy_cdf(x, mu, sigma)\n",
    "\n",
    "    # needed so that we can hack iminuit's introspection to function parameter names.\n",
    "    def norm_pdf(\n",
    "        self, x: np.ndarray, x_lower: float, x_upper: float, mu: float, sigma: float\n",
    "    ) -> np.ndarray:\n",
    "        return self._norm_pdf(x, x_lower, x_upper, mu, sigma)\n",
    "\n",
    "    def norm_cdf(\n",
    "        self, x: np.ndarray, x_lower: float, x_upper: float, mu: float, sigma: float\n",
    "    ) -> np.ndarray:\n",
    "        return self._norm_cdf(x, x_lower, x_upper, mu, sigma)\n",
    "\n",
    "    def pdf_ext(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        area: float,\n",
    "        x_lower: float,\n",
    "        x_upper: float,\n",
    "        mu: float,\n",
    "        sigma: float,\n",
    "    ) -> np.ndarray:\n",
    "        return np.diff(\n",
    "            nb_cauchy_scaled_cdf(np.array([x_lower, x_upper]), area, mu, sigma)\n",
    "        ), nb_cauchy_scaled_pdf(x, area, mu, sigma)\n",
    "\n",
    "    def cdf_ext(\n",
    "        self, x: np.ndarray, area: float, mu: float, sigma: float\n",
    "    ) -> np.ndarray:\n",
    "        return nb_cauchy_scaled_cdf(x, area, mu, sigma)\n",
    "\n",
    "    def required_args(self) -> tuple[str, str]:\n",
    "        return \"mu\", \"sigma\"\n",
    "\n",
    "\n",
    "cauchy = cauchy_gen(name=\"cauchy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import cauchy as scipy_cauchy\n",
    "\n",
    "cauchy_pdf = cauchy.pdf(x, mu, sigma)\n",
    "cauchy_get_pdf = cauchy.get_pdf(x, mu, sigma)\n",
    "\n",
    "cauchy_cdf = cauchy.cdf(x, mu, sigma)\n",
    "cauchy_get_cdf = cauchy.get_cdf(x, mu, sigma)\n",
    "\n",
    "plt.plot(x, cauchy_pdf, label=\"Pygama Cauchy PDF\", c=\"k\")\n",
    "plt.plot(x, cauchy_get_pdf, label=\"Pygama Cauchy get_pdf\", c=\"b\", ls=\"--\")\n",
    "plt.plot(\n",
    "    x, scipy_cauchy.pdf(x, mu, sigma), label=\"Scipy Cauchy PDF\", ls=\":\", alpha=1, c=\"r\"\n",
    ")\n",
    "plt.title(\"PDF of a Cauchy Distribution\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(x, cauchy_cdf, label=\"Pygama Cauchy CDF\", c=\"k\")\n",
    "plt.plot(x, cauchy_get_cdf, label=\"Pygama Cauchy get_cdf\", c=\"b\", ls=\"--\")\n",
    "plt.plot(\n",
    "    x, scipy_cauchy.cdf(x, mu, sigma), label=\"Scipy Cauchy CDF\", ls=\":\", alpha=1, c=\"r\"\n",
    ")\n",
    "plt.title(\"CDF of a Cauchy Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform some fits using the new Cauchy distribution to show the other methods' validity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr = (-4, 4)  # xrange\n",
    "mu = 0.5\n",
    "sigma = 0.7\n",
    "\n",
    "xdata = scipy_cauchy.rvs(mu, sigma, size=1000, random_state=42)\n",
    "xdata = xdata[(xr[0] < xdata) & (xdata < xr[1])]\n",
    "\n",
    "n, xe = np.histogram(xdata, bins=50, range=xr)\n",
    "cx = 0.5 * (xe[1:] + xe[:-1])\n",
    "dx = np.diff(xe)\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "plt.plot(xdata, np.zeros_like(xdata), \"|\", alpha=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unbinned fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.UnbinnedNLL(xdata, cauchy.norm_pdf)\n",
    "\n",
    "m_norm = Minuit(c, x_lower=xr[0], x_upper=xr[1], mu=0.4, sigma=0.2)\n",
    "m_norm.fixed[\"x_lower\", \"x_upper\"] = True\n",
    "m_norm.limits[\"mu\", \"sigma\"] = (0, None)\n",
    "m_norm.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extended unbinned fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedUnbinnedNLL(xdata, cauchy.pdf_ext)\n",
    "\n",
    "m = Minuit(c, area=500, x_lower=xr[0], x_upper=xr[1], mu=0.1, sigma=0.9)\n",
    "m.fixed[\"x_lower\", \"x_upper\"] = True\n",
    "m.limits[\"area\", \"mu\", \"sigma\"] = (0.01, None)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binned fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.BinnedNLL(n, xe, cauchy.norm_cdf)\n",
    "\n",
    "m_norm = Minuit(c, x_lower=xr[0], x_upper=xr[1], mu=0.4, sigma=0.2)\n",
    "m_norm.fixed[\"x_lower\", \"x_upper\"] = True\n",
    "m_norm.limits[\"mu\", \"sigma\"] = (0.1, None)\n",
    "m_norm.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended binned fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedBinnedNLL(n, xe, cauchy.cdf_ext)\n",
    "\n",
    "m = Minuit(c, area=500, mu=0.1, sigma=0.9)\n",
    "m.limits[\"area\", \"mu\", \"sigma\"] = (0, None)\n",
    "m.migrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding distributions with `sum_dists`\n",
    "\n",
    "In the business of fitting data, adding two distributions together is our bread-and-butter. This part of the notebook will show you how to create your own distribution that subclasses `pygama.math.sum_dists`. There are a couple of different use cases for adding distributions together, and we will look at each in turn, but here is a summary:\n",
    "\n",
    "1. Adding different fractions of distributions together, and fitting out the relative amount of distributions\n",
    "2. Adding distributions with different areas (present in equal fractions) and fitting the areas \n",
    "3. Adding distributions with different areas that have different fractions, and fitting out the areas and fractions \n",
    "\n",
    "### Let's first create the synthetic data that we will fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr = (-4, 4)  # xrange\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "mu = 0.5\n",
    "sigma = 1.3\n",
    "\n",
    "mu2 = 1\n",
    "sigma2 = 0.6\n",
    "\n",
    "\n",
    "xdata = norm.rvs(mu, sigma, size=1000, random_state=42)\n",
    "ydata = scipy_cauchy.rvs(mu2, sigma2, size=len(xdata), random_state=42)\n",
    "xmix = np.append(xdata, ydata)\n",
    "xmix = xmix[(xr[0] < xmix) & (xmix < xr[1])]\n",
    "\n",
    "n, xe = np.histogram(xmix, bins=50, range=xr)\n",
    "cx = 0.5 * (xe[1:] + xe[:-1])\n",
    "dx = np.diff(xe)\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "plt.plot(xmix, np.zeros_like(xmix), \"|\", alpha=0.1);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A little about `sum_dists`\n",
    "The first important thing to note about this class is that all method class are of the form `method(x, parameter_array)`. We want to use a single array as an argument because we need to accommodate an arbitrarily large number of parameters. In addition, a single array is an acceptable input for `Iminuit` fits. \n",
    "\n",
    "So, the first thing a user does in creating a new class is define the order of elements in a `parameter_array`. Now, `sum_dists` works by grabbing elements at different indices in this `parameter_array` according to rules that the user provides in the `__init__`. Here's how to write a generic class: \n",
    "\n",
    "1. Create a `parameter_index_array` that holds the indices of what will eventually come in the `parameter_array`. If the user will eventually pass `parameters = [frac1, mu, sigma]` then we just take `parameter_index_array=[frac1, mu, sigma]=range(3)`\n",
    "\n",
    "2. `sum_dists` takes an alternating pattern of distributions and distribution-specific parameter_index_arrays. Each par array can contain `[shape, mu, sigma, area, frac]` with area and frac being optional (depending on the flag sent to the constructor) but *must be placed in that order*. \n",
    "\n",
    "3. We pass one of the 4 flag options, to be described below. \n",
    "\n",
    "Let's trace through how the code works for a simple example. Suppose we want to create the following distribution \n",
    "\n",
    "$new\\_pdf(x, [\\tau, \\mu, \\sigma, frac_1, frac_2]) = frac_1\\cdot dist_1(x, \\tau, \\mu, \\sigma) + frac_2\\cdot dist_2(x, \\mu, \\sigma)$\n",
    "\n",
    "The first thing we would do is create our `parameter_index_array` \n",
    "\n",
    "`[tau, mu, sigma, frac_1, frac_2] = range(5)`\n",
    "\n",
    "Then, we would create our alternating pattern of distributions and parameter index arrays:\n",
    "\n",
    "`args = [dist1, [tau, mu, sigma, frac_1], dist2, [mu, sigma, frac2]]`\n",
    "\n",
    "Finally, we would intitalize (with the `fracs` flag in this case, more on that later) \n",
    "\n",
    "`super().__init__(*args, frac_flag = \"fracs\")`\n",
    "\n",
    "## So... What is `sum_dists` actually doing? \n",
    "Under the hood, `sum_dists` is applying a set of rules so that the following *is always* computed, regardless of the flag sent to the constructor. \n",
    "\n",
    "`total_area*area1*frac1*dist1(x, shape, mu, sigma) + ... total_area*area_n*frac_n*dist_n(x, shape_1, mu_n, sigma_n)`\n",
    "\n",
    "It does this by first reading through all of the parameter index arrays for each distribution and separating the indices for the shape parameters, areas, and fracs into separate index arrays. Then, at the time of method call, these separate parameter index arrays are used to grab the actual values for the shape parameters, fractions, and areas. \n",
    "There's also some work done to determine which of `area` and `frac` are present. That's the purpose of the `frac_flag`. Let's take some time and learn a little more about what each flag does. \n",
    " \n",
    "\n",
    "\n",
    "## The `areas` flag in the `sum_dists` constructor\n",
    "Let's say we are interested in knowing the amount of counts present in a signal and a background in our total spectrum, i.e. we want to create and fit a function that looks like\n",
    "\n",
    "$pdf= A\\cdot gauss\\_pdf + B\\cdot cauchy\\_pdf$\n",
    "\n",
    "Because we are interested in fitting the areas, we send the `areas` keyword to `frac_flag`. This causes `sum_dists` to assume that *the last element in each parameter index array in the constructor is an area for that specific distribution*. By default, all the `fracs` are set to 1, as well as the `total_area`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygama.math.functions.sum_dists import sum_dists\n",
    "\n",
    "\n",
    "class cauchy_on_gauss_gen(sum_dists):\n",
    "    def __init__(self):\n",
    "        # we first create an array contains the indices of the parameter array\n",
    "        # that will eventually be input to function calls\n",
    "        (area1, mu, sigma, area2, mu2, sigma2) = range(6)\n",
    "\n",
    "        # we now create an array containing the distributions and their shape parameters\n",
    "        # The last item in a parameter array is the fraction or area component\n",
    "        # The last item in the last parameter array corresponds to the total area, if present\n",
    "        # but because we are fitting individual areas, the total area is meaningless\n",
    "        args = [gaussian, [mu, sigma, area1], cauchy, [mu2, sigma2, area2]]\n",
    "        # we initialize with the frac_flag = \"areas\" to let the constructor know we are sending frac parameters only\n",
    "        super().__init__(*args, frac_flag=\"areas\")\n",
    "\n",
    "    def get_req_args(self) -> tuple[str, str, str]:\n",
    "        r\"\"\"\n",
    "        Return the required arguments for this instance\n",
    "        \"\"\"\n",
    "        return \"area1\", \"mu\", \"sigma\", \"area2\", \"mu2\", \"sigma2\"\n",
    "\n",
    "\n",
    "cauchy_on_gauss = cauchy_on_gauss_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was super quick, let's see how it does with fitting data\n",
    "\n",
    "Because we are interested in fitting out areas, we need to use the extended forms of our fits \n",
    "And for `pdf_ext` methods we have two options: we either pass `x_lo, x_hi` at the start of our parameter array, or we don't pass them and the function automatically takes the `np.amin(x), np.amax(x)` as those values \n",
    "\n",
    "## something to note: all parameter arrays passed to `sum_dist` methods *must* be `numpy` arrays; for example, see that we must turn `m.values` into `np.array(m.values)` in order for it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedUnbinnedNLL(xmix, cauchy_on_gauss.pdf_ext)\n",
    "\n",
    "m = Minuit(c, (xr[0], xr[1], 100, 0.1, 0.3, 100, 1, 2))\n",
    "m.fixed[0, 1] = True  # fix the x_lo, x_hi\n",
    "m.limits[2, 5] = (0, None)\n",
    "m.limits[3, 4, 6, 7] = (0, 2)\n",
    "print(m.migrad())\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "xm = np.linspace(*xr)\n",
    "plt.plot(xm, cauchy_on_gauss.pdf_ext(xm, np.array(m.values))[1] * dx[0], label=\"fit\")\n",
    "plt.plot(\n",
    "    xm,\n",
    "    cauchy_on_gauss.pdf_ext(xm, np.array([1000, mu, sigma, 1000, mu2, sigma2]))[1]\n",
    "    * dx[0],\n",
    "    label=\"actual\",\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's pretty good! Let's see how the extended unbinned fit fairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedBinnedNLL(n, xe, cauchy_on_gauss.cdf_ext)\n",
    "m = Minuit(c, (100, 0.1, 0.3, 100, 1, 2))\n",
    "m.limits[0, 3] = (0, None)\n",
    "m.limits[1, 2, 4, 5] = (0, 2)\n",
    "print(m.migrad())\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "plt.stairs(np.diff(cauchy_on_gauss.cdf_ext(xe, np.array(m.values))), xe, label=\"fit\")\n",
    "plt.stairs(\n",
    "    np.diff(\n",
    "        cauchy_on_gauss.cdf_ext(xe, np.array([1000, mu, sigma, 1000, mu2, sigma2]))\n",
    "    ),\n",
    "    xe,\n",
    "    label=\"actual\",\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `fracs` flag in the `sum_dists` constructor\n",
    "To get a feel for how `sum_dists` works, let's create a function that creates the following distribution:\n",
    "\n",
    "$pdf = f_1\\cdot gauss\\_{pdf}+(1-f_1)\\cdot cauchy\\_{pdf}$\n",
    "\n",
    "Well, it might seem crazy, but we can actually link together parameters before they are fit! That's the beauty of the parameter index array and the `link_pars` function that we can overload.\n",
    "\n",
    "The `fracs` keyword causes `sum_dists` to assume the following about the parameter index arrays in the `__init__`: each parameter index array looks like `[shapes, mu, sigma, frac]` with the exception of the last parameter index array which has the form `[shapes, mu, sigma, frac, total_area]`. \n",
    "\n",
    "Well, what if we don't care about `total_area`? Or, what if we want to link parameters, like the `f_1` value in the above example? That's where `link_pars` comes in. Nominally, `link_pars` serves to extract the actual values of the shapes, fracs, and areas from the passed parameter array. But, if we overload it, we can actually link the parameters together! See the below code for an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygama.math.functions.sum_dists import sum_dists\n",
    "\n",
    "\n",
    "class cauchy_on_gauss_gen(sum_dists):\n",
    "    def __init__(self):\n",
    "        # we first create an array contains the indices of the parameter array\n",
    "        # that will eventually be input to function calls\n",
    "        (frac1, mu, sigma, mu2, sigma2) = range(5)\n",
    "\n",
    "        # we now create an array containing the distributions and their shape parameters\n",
    "        # The last item in a parameter array is the fraction or area component\n",
    "        # The last item in the last parameter array corresponds to the total area if present\n",
    "        args = [gaussian, [mu, sigma, frac1], cauchy, [mu2, sigma2, frac1, frac1]]\n",
    "        # we initialize with the frac_flag = \"fracs\" to let the constructor know we are sending frac parameters only\n",
    "        super().__init__(*args, frac_flag=\"fracs\")\n",
    "\n",
    "    def _link_pars(\n",
    "        self,\n",
    "        shape_par_idx,\n",
    "        area_idx,\n",
    "        frac_idx,\n",
    "        total_area_idx,\n",
    "        params,\n",
    "        areas,\n",
    "        fracs,\n",
    "        total_area,\n",
    "    ):\n",
    "        shape_pars, cum_len, areas, fracs, total_area = super()._link_pars(\n",
    "            shape_par_idx,\n",
    "            area_idx,\n",
    "            frac_idx,\n",
    "            total_area_idx,\n",
    "            params,\n",
    "            areas,\n",
    "            fracs,\n",
    "            total_area,\n",
    "        )\n",
    "\n",
    "        fracs[1] = (\n",
    "            1 - fracs[0]\n",
    "        )  # create :math:`(1-frac1)` for the cauchy, and :math:`frac1` for the exgauss\n",
    "        total_area[\n",
    "            0\n",
    "        ] = 1  # just overwrite the total area because we don't want to fit it\n",
    "\n",
    "        return shape_pars, cum_len, areas, fracs, total_area\n",
    "\n",
    "    def get_req_args(self) -> tuple[str, str, str]:\n",
    "        r\"\"\"\n",
    "        Return the required arguments for this instance\n",
    "        \"\"\"\n",
    "        return \"frac1\", \"mu\", \"sigma\", \"mu2\", \"sigma2\"\n",
    "\n",
    "\n",
    "cauchy_on_gauss = cauchy_on_gauss_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, that was painless; let's see how well it does fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.UnbinnedNLL(xmix, cauchy_on_gauss.norm_pdf)\n",
    "\n",
    "m = Minuit(c, (xr[0], xr[1], 0.5, 0.1, 0.2, 1, 0.1))\n",
    "m.fixed[0, 1] = True\n",
    "m.limits[2] = (0, 1)\n",
    "m.limits[3, 4, 5, 6] = (0.5, 2)\n",
    "print(m.migrad())\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "xm = np.linspace(*xr)\n",
    "plt.plot(\n",
    "    xm,\n",
    "    cauchy_on_gauss.norm_pdf(xm, np.array(m.values)) * len(xmix) * dx[0],\n",
    "    label=\"fit\",\n",
    ")\n",
    "plt.plot(\n",
    "    xm,\n",
    "    cauchy_on_gauss.get_pdf(xm, np.array([0.5, mu, sigma, mu2, sigma2]))\n",
    "    * len(xmix)\n",
    "    * dx[0],\n",
    "    label=\"actual\",\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `both` flag in the `sum_dists` constructor \n",
    "\n",
    "What if we wanted to find the signal and background counts for distributions that share unequal fractions? I.e. what if we want to construct the following: \n",
    "\n",
    "$pdf = Af_1\\cdot gauss\\_{pdf}+B(1-f_1)\\cdot cauchy\\_{pdf}$\n",
    "\n",
    "It's easy! We use the `both` flag! \n",
    "\n",
    "The `both` keywords causes `sum_dists` to look for ordering of parameters in each index array like `[shape, mu, sigma, area, frac]`, except the last parameter array index must have the form `[shape, mu, sigma, area, frac, total_area]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygama.math.functions.sum_dists import sum_dists\n",
    "\n",
    "\n",
    "class cauchy_on_gauss_gen(sum_dists):\n",
    "    def __init__(self):\n",
    "        # we first create an array contains the indices of the parameter array\n",
    "        # that will eventually be input to function calls\n",
    "        (area1, frac1, mu, sigma, area2, mu2, sigma2) = range(7)\n",
    "\n",
    "        # we now create an array containing the distributions and their shape parameters\n",
    "        # The last item in a parameter array is the fraction or area component\n",
    "        # The last item in the last parameter array corresponds to the total area if present\n",
    "        args = [\n",
    "            gaussian,\n",
    "            [mu, sigma, area1, frac1],\n",
    "            cauchy,\n",
    "            [mu2, sigma2, area2, frac1, frac1],\n",
    "        ]\n",
    "        # we initialize with the frac_flag = \"fracs\" to let the constructor know we are sending frac parameters only\n",
    "        super().__init__(*args, frac_flag=\"both\")\n",
    "\n",
    "    def _link_pars(\n",
    "        self,\n",
    "        shape_par_idx,\n",
    "        area_idx,\n",
    "        frac_idx,\n",
    "        total_area_idx,\n",
    "        params,\n",
    "        areas,\n",
    "        fracs,\n",
    "        total_area,\n",
    "    ):\n",
    "        shape_pars, cum_len, areas, fracs, total_area = super()._link_pars(\n",
    "            shape_par_idx,\n",
    "            area_idx,\n",
    "            frac_idx,\n",
    "            total_area_idx,\n",
    "            params,\n",
    "            areas,\n",
    "            fracs,\n",
    "            total_area,\n",
    "        )\n",
    "\n",
    "        fracs[1] = (\n",
    "            1 - fracs[0]\n",
    "        )  # create :math:`(1-frac1)` for the gaussian, and :math:`htail` for the exgauss\n",
    "        total_area[\n",
    "            0\n",
    "        ] = 1  # just overwrite the total area because we don't want to fit it\n",
    "\n",
    "        return shape_pars, cum_len, areas, fracs, total_area\n",
    "\n",
    "    def get_req_args(self) -> tuple[str, str, str]:\n",
    "        r\"\"\"\n",
    "        Return the required arguments for this instance\n",
    "        \"\"\"\n",
    "        return \"area1\", \"frac1\", \"mu\", \"sigma\", \"area2\", \"mu2\", \"sigma2\"\n",
    "\n",
    "\n",
    "cauchy_on_gauss = cauchy_on_gauss_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedUnbinnedNLL(xmix, cauchy_on_gauss.pdf_ext)\n",
    "\n",
    "m = Minuit(c, (xr[0], xr[1], 100, 0.1, 0.1, 0.3, 100, 1, 2))\n",
    "m.fixed[0, 1] = True  # fix the x_lo, x_hi\n",
    "m.limits[2, 6] = (0, None)\n",
    "m.limits[3] = (0, 1)\n",
    "m.limits[4, 5, 7, 8] = (0, 2)\n",
    "print(m.migrad())\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "xm = np.linspace(*xr)\n",
    "plt.plot(xm, cauchy_on_gauss.pdf_ext(xm, np.array(m.values))[1] * dx[0], label=\"fit\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see if that last fit agrees with a fit from a function we would define \"by hand\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy_gauss_pdf_ext(x, x_lo, x_hi, A, B, frac, mu, sigma, mu2, sigma2):\n",
    "    return A * frac * np.diff(\n",
    "        gaussian.get_cdf(np.array([x_lo, x_hi]), mu, sigma)\n",
    "    ) + B * (1 - frac) * np.diff(\n",
    "        cauchy.get_cdf(np.array([x_lo, x_hi]), mu2, sigma2)\n",
    "    ), A * frac * gaussian.get_pdf(\n",
    "        x, mu, sigma\n",
    "    ) + (\n",
    "        1 - frac\n",
    "    ) * B * cauchy.get_pdf(\n",
    "        x, mu2, sigma2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cost.ExtendedUnbinnedNLL(xmix, cauchy_gauss_pdf_ext)\n",
    "\n",
    "m = Minuit(c, xr[0], xr[1], 100, 100, 0.1, 0.1, 0.3, 1, 2)\n",
    "m.fixed[0, 1] = True  # fix the x_lo, x_hi\n",
    "m.limits[2, 3] = (0, None)\n",
    "m.limits[4] = (0, 1)\n",
    "m.limits[5, 6, 7, 8] = (0, 2)\n",
    "print(m.migrad())\n",
    "\n",
    "plt.errorbar(cx, n, n**0.5, fmt=\"ok\")\n",
    "xm = np.linspace(*xr)\n",
    "plt.plot(xm, cauchy_gauss_pdf_ext(xm, *m.values)[1] * dx[0], label=\"fit\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `sum_dists` reproduces results quickly and without the need for spending time writing new methods for each of the summed distributions. \n",
    "\n",
    "# Conclusion \n",
    "Hopefully you have learned how to use the distributions and tools packaged in `pygama` for your own scientific purposes. If there's a distribution you see is missing, feel free to contribute it using the conventions described above! "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
